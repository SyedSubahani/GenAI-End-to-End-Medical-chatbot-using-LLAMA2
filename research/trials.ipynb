{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone as PineconeLang\n",
    "from pinecone import Pinecone as PineconeClient \n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_API_ENV = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"PINECONE_API_ENV\"] = PINECONE_API_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data = load_pdf(\"data/\")\n",
    "extracted_data = load_pdf(r\"C:\\Users\\smsub\\Subahani\\Study\\Generative AI\\chatbotLlama2\\GenAI-End-to-End-Medical-chatbot-using-LLAMA2\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='', metadata={'source': 'C:\\\\Users\\\\smsub\\\\Subahani\\\\Study\\\\Generative AI\\\\chatbotLlama2\\\\GenAI-End-to-End-Medical-chatbot-using-LLAMA2\\\\data\\\\Medical_book.pdf', 'page': 0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 7020\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TheGALE\\nENCYCLOPEDIA\\nofMEDICINE\\nSECOND EDITION'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.034477222710847855,\n",
       " 0.031023189425468445,\n",
       " 0.00673493230715394,\n",
       " 0.02610897831618786,\n",
       " -0.03936203941702843,\n",
       " -0.16030248999595642,\n",
       " 0.06692398339509964,\n",
       " -0.006441492587327957,\n",
       " -0.04745054617524147,\n",
       " 0.01475894171744585,\n",
       " 0.07087540626525879,\n",
       " 0.05552757903933525,\n",
       " 0.019193286076188087,\n",
       " -0.026251375675201416,\n",
       " -0.010109512135386467,\n",
       " -0.026940539479255676,\n",
       " 0.022307513281702995,\n",
       " -0.022226620465517044,\n",
       " -0.14969266951084137,\n",
       " -0.017493048682808876,\n",
       " 0.00767626753076911,\n",
       " 0.0543522946536541,\n",
       " 0.003254437353461981,\n",
       " 0.03172598034143448,\n",
       " -0.0846213847398758,\n",
       " -0.029406018555164337,\n",
       " 0.05159567669034004,\n",
       " 0.048124030232429504,\n",
       " -0.0033148014917969704,\n",
       " -0.05827920511364937,\n",
       " 0.04196932911872864,\n",
       " 0.022210698574781418,\n",
       " 0.12818889319896698,\n",
       " -0.022338908165693283,\n",
       " -0.011656295508146286,\n",
       " 0.06292832642793655,\n",
       " -0.03287626430392265,\n",
       " -0.09122607111930847,\n",
       " -0.03117542713880539,\n",
       " 0.052699606865644455,\n",
       " 0.0470348484814167,\n",
       " -0.08420299738645554,\n",
       " -0.030056146904826164,\n",
       " -0.020744740962982178,\n",
       " 0.009517806582152843,\n",
       " -0.003721754066646099,\n",
       " 0.007343400735408068,\n",
       " 0.0393243245780468,\n",
       " 0.09327412396669388,\n",
       " -0.003788660280406475,\n",
       " -0.05274209380149841,\n",
       " -0.058058179914951324,\n",
       " -0.006864393129944801,\n",
       " 0.005283208563923836,\n",
       " 0.08289302885532379,\n",
       " 0.019362719729542732,\n",
       " 0.006284467875957489,\n",
       " -0.010330799035727978,\n",
       " 0.009032361209392548,\n",
       " -0.03768374025821686,\n",
       " -0.04520608112215996,\n",
       " 0.024016406387090683,\n",
       " -0.006944221444427967,\n",
       " 0.013491588644683361,\n",
       " 0.1000550389289856,\n",
       " -0.07168388366699219,\n",
       " -0.021695110946893692,\n",
       " 0.031618498265743256,\n",
       " -0.05163465067744255,\n",
       " -0.08224771171808243,\n",
       " -0.06569333374500275,\n",
       " -0.009895400144159794,\n",
       " 0.005816393531858921,\n",
       " 0.07355456799268723,\n",
       " -0.034050289541482925,\n",
       " 0.02488614059984684,\n",
       " 0.014488041400909424,\n",
       " 0.02645743079483509,\n",
       " 0.009656773880124092,\n",
       " 0.030217353254556656,\n",
       " 0.05280391499400139,\n",
       " -0.07535991817712784,\n",
       " 0.009897246025502682,\n",
       " 0.029836872592568398,\n",
       " 0.01755552366375923,\n",
       " 0.02309202030301094,\n",
       " 0.0019339160062372684,\n",
       " 0.0014001699164509773,\n",
       " -0.04717598110437393,\n",
       " -0.011194389313459396,\n",
       " -0.1142013669013977,\n",
       " -0.01981193758547306,\n",
       " 0.04026619344949722,\n",
       " 0.002193003660067916,\n",
       " -0.07979225367307663,\n",
       " -0.025382278487086296,\n",
       " 0.0944829136133194,\n",
       " -0.028981145471334457,\n",
       " -0.14500252902507782,\n",
       " 0.23097746074199677,\n",
       " 0.027731088921427727,\n",
       " 0.032111458480358124,\n",
       " 0.031065048649907112,\n",
       " 0.0428328663110733,\n",
       " 0.06423778831958771,\n",
       " 0.03216320648789406,\n",
       " -0.0048766350373625755,\n",
       " 0.05569944530725479,\n",
       " -0.037532344460487366,\n",
       " -0.021505599841475487,\n",
       " -0.028342677280306816,\n",
       " -0.028846919536590576,\n",
       " 0.03835314139723778,\n",
       " -0.017468657344579697,\n",
       " 0.052485305815935135,\n",
       " -0.07487601041793823,\n",
       " -0.031259771436452866,\n",
       " 0.02184155397117138,\n",
       " -0.03989563137292862,\n",
       " -0.008587107993662357,\n",
       " 0.026956642046570778,\n",
       " -0.0484955720603466,\n",
       " 0.011469881981611252,\n",
       " 0.029618272557854652,\n",
       " -0.02057218924164772,\n",
       " 0.01310393214225769,\n",
       " 0.02883334830403328,\n",
       " -3.194198717480234e-33,\n",
       " 0.06478200852870941,\n",
       " -0.018130198121070862,\n",
       " 0.05178993195295334,\n",
       " 0.12198270857334137,\n",
       " 0.028780151158571243,\n",
       " 0.008722010999917984,\n",
       " -0.07052118331193924,\n",
       " -0.016907328739762306,\n",
       " 0.040739756077528,\n",
       " 0.042116232216358185,\n",
       " 0.025447258725762367,\n",
       " 0.03574620187282562,\n",
       " -0.04914474859833717,\n",
       " 0.0021291167940944433,\n",
       " -0.015546612441539764,\n",
       " 0.05073057487607002,\n",
       " -0.04818534106016159,\n",
       " 0.035880595445632935,\n",
       " -0.00406709173694253,\n",
       " 0.10172467678785324,\n",
       " -0.05597005411982536,\n",
       " -0.010681030340492725,\n",
       " 0.011235793121159077,\n",
       " 0.09068653732538223,\n",
       " 0.004234467167407274,\n",
       " 0.03513869643211365,\n",
       " -0.00970284640789032,\n",
       " -0.09386520087718964,\n",
       " 0.0928555503487587,\n",
       " 0.008004946634173393,\n",
       " -0.0077055045403540134,\n",
       " -0.0520867183804512,\n",
       " -0.01258792169392109,\n",
       " 0.003266914514824748,\n",
       " 0.0060135480016469955,\n",
       " 0.00758166192099452,\n",
       " 0.010517152957618237,\n",
       " -0.08634547889232635,\n",
       " -0.0698787271976471,\n",
       " -0.0025338272098451853,\n",
       " -0.09097656607627869,\n",
       " 0.046887341886758804,\n",
       " 0.05207650735974312,\n",
       " 0.007193916942924261,\n",
       " 0.010903612710535526,\n",
       " -0.0052295564673841,\n",
       " 0.013937313109636307,\n",
       " 0.021968349814414978,\n",
       " 0.034208618104457855,\n",
       " 0.06022460386157036,\n",
       " 0.00011661827738862485,\n",
       " 0.014731953851878643,\n",
       " -0.0700891837477684,\n",
       " 0.02849903330206871,\n",
       " -0.027601581066846848,\n",
       " 0.010768389329314232,\n",
       " 0.03483093902468681,\n",
       " -0.022487882524728775,\n",
       " 0.00976910162717104,\n",
       " 0.07722782343626022,\n",
       " 0.021588314324617386,\n",
       " 0.11495622247457504,\n",
       " -0.0680011510848999,\n",
       " 0.023761004209518433,\n",
       " -0.015983946621418,\n",
       " -0.01782703399658203,\n",
       " 0.06439494341611862,\n",
       " 0.032025761902332306,\n",
       " 0.05027030035853386,\n",
       " -0.005913687404245138,\n",
       " -0.033708006143569946,\n",
       " 0.01784031093120575,\n",
       " 0.016573360189795494,\n",
       " 0.06329651921987534,\n",
       " 0.03467719256877899,\n",
       " 0.04647350311279297,\n",
       " 0.09790613502264023,\n",
       " -0.006635547615587711,\n",
       " 0.025207022204995155,\n",
       " -0.07798837870359421,\n",
       " 0.01692640222609043,\n",
       " -0.0009458923595957458,\n",
       " 0.02247190661728382,\n",
       " -0.03825324401259422,\n",
       " 0.09570476412773132,\n",
       " -0.005350665654987097,\n",
       " 0.0104690445587039,\n",
       " -0.11524055153131485,\n",
       " -0.013262517750263214,\n",
       " -0.010709403082728386,\n",
       " -0.08311717957258224,\n",
       " 0.07327355444431305,\n",
       " 0.049392182379961014,\n",
       " -0.008994391188025475,\n",
       " -0.0958455428481102,\n",
       " 3.366148929092564e-33,\n",
       " 0.12493182718753815,\n",
       " 0.019349761307239532,\n",
       " -0.058225780725479126,\n",
       " -0.0359882190823555,\n",
       " -0.05074676498770714,\n",
       " -0.04566236585378647,\n",
       " -0.08260341733694077,\n",
       " 0.14819474518299103,\n",
       " -0.08842108398675919,\n",
       " 0.06027445197105408,\n",
       " 0.051030226051807404,\n",
       " 0.010303134098649025,\n",
       " 0.14121423661708832,\n",
       " 0.03081386350095272,\n",
       " 0.061033058911561966,\n",
       " -0.052851323038339615,\n",
       " 0.13664887845516205,\n",
       " 0.009189879521727562,\n",
       " -0.017325259745121002,\n",
       " -0.012848688289523125,\n",
       " -0.007995298132300377,\n",
       " -0.05098012089729309,\n",
       " -0.052350662648677826,\n",
       " 0.007593042217195034,\n",
       " -0.01516624167561531,\n",
       " 0.01696031354367733,\n",
       " 0.021270539611577988,\n",
       " 0.020557962357997894,\n",
       " -0.1200280711054802,\n",
       " 0.014461783692240715,\n",
       " 0.026759838685393333,\n",
       " 0.025330523028969765,\n",
       " -0.0427546389400959,\n",
       " 0.006768465507775545,\n",
       " -0.014458563178777695,\n",
       " 0.04526202008128166,\n",
       " -0.09147657454013824,\n",
       " -0.01943924091756344,\n",
       " -0.017833463847637177,\n",
       " -0.05491016060113907,\n",
       " -0.0526411347091198,\n",
       " -0.010459073819220066,\n",
       " -0.052016064524650574,\n",
       " 0.020892024040222168,\n",
       " -0.0799703299999237,\n",
       " -0.012111270800232887,\n",
       " -0.05773139372467995,\n",
       " 0.023178229108452797,\n",
       " -0.008031618781387806,\n",
       " -0.025989316403865814,\n",
       " -0.07995668798685074,\n",
       " -0.02072881907224655,\n",
       " 0.04881777614355087,\n",
       " -0.02038918249309063,\n",
       " -0.04917668178677559,\n",
       " 0.01415963750332594,\n",
       " -0.06362202018499374,\n",
       " -0.007807393092662096,\n",
       " 0.016431521624326706,\n",
       " -0.025682564824819565,\n",
       " 0.013381000608205795,\n",
       " 0.026248749345541,\n",
       " 0.00997837632894516,\n",
       " 0.06322889029979706,\n",
       " 0.0026720971800386906,\n",
       " -0.0065827397629618645,\n",
       " 0.016631998121738434,\n",
       " 0.032366421073675156,\n",
       " 0.037942446768283844,\n",
       " -0.03637601435184479,\n",
       " -0.006910947151482105,\n",
       " 0.00015970191452652216,\n",
       " -0.0016336289700120687,\n",
       " -0.02727821096777916,\n",
       " -0.028038067743182182,\n",
       " 0.049681518226861954,\n",
       " -0.02886717952787876,\n",
       " -0.0024179979227483273,\n",
       " 0.014774901792407036,\n",
       " 0.009764573536813259,\n",
       " 0.005797533318400383,\n",
       " 0.013486129231750965,\n",
       " 0.005567885935306549,\n",
       " 0.037227142602205276,\n",
       " 0.0072325305081903934,\n",
       " 0.04015626385807991,\n",
       " 0.08150319010019302,\n",
       " 0.07199164479970932,\n",
       " -0.01305612176656723,\n",
       " -0.04288197681307793,\n",
       " -0.011011216789484024,\n",
       " 0.004897784907370806,\n",
       " -0.009229699149727821,\n",
       " 0.035191554576158524,\n",
       " -0.05103496462106705,\n",
       " -1.571437557856825e-08,\n",
       " -0.08862447738647461,\n",
       " 0.023909317329525948,\n",
       " -0.016238749027252197,\n",
       " 0.03170045465230942,\n",
       " 0.027284180745482445,\n",
       " 0.05246885493397713,\n",
       " -0.047070931643247604,\n",
       " -0.05884741619229317,\n",
       " -0.06320826709270477,\n",
       " 0.040888555347919464,\n",
       " 0.04982791095972061,\n",
       " 0.1065516397356987,\n",
       " -0.07450234144926071,\n",
       " -0.012495470233261585,\n",
       " 0.01837068982422352,\n",
       " 0.03947412595152855,\n",
       " -0.024797873571515083,\n",
       " 0.014516300521790981,\n",
       " -0.03706924617290497,\n",
       " 0.02001567929983139,\n",
       " -4.859203181695193e-05,\n",
       " 0.009866567328572273,\n",
       " 0.024838829413056374,\n",
       " -0.05245809257030487,\n",
       " 0.02931414544582367,\n",
       " -0.08719193935394287,\n",
       " -0.014499787241220474,\n",
       " 0.026019079610705376,\n",
       " -0.01874641887843609,\n",
       " -0.07620512694120407,\n",
       " 0.03504328802227974,\n",
       " 0.10363954305648804,\n",
       " -0.028050515800714493,\n",
       " 0.01271822303533554,\n",
       " -0.07632546871900558,\n",
       " -0.018652385100722313,\n",
       " 0.024976631626486778,\n",
       " 0.08144541829824448,\n",
       " 0.06875895708799362,\n",
       " -0.06405667960643768,\n",
       " -0.08389390259981155,\n",
       " 0.061362382024526596,\n",
       " -0.033545609563589096,\n",
       " -0.10615337640047073,\n",
       " -0.04008055850863457,\n",
       " 0.03253021836280823,\n",
       " 0.0766248106956482,\n",
       " -0.07301609963178635,\n",
       " 0.0003375708474777639,\n",
       " -0.04087156429886818,\n",
       " -0.07578849047422409,\n",
       " 0.027527712285518646,\n",
       " 0.07462546229362488,\n",
       " 0.01771734096109867,\n",
       " 0.09121840447187424,\n",
       " 0.11022021621465683,\n",
       " 0.0005698088789358735,\n",
       " 0.05146335810422897,\n",
       " -0.01455130334943533,\n",
       " 0.033232010900974274,\n",
       " 0.02379230223596096,\n",
       " -0.022889776155352592,\n",
       " 0.03893757238984108,\n",
       " 0.030206819996237755]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the Pinecone\n",
    "pc = PineconeClient(api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "                    environment=os.environ[\"PINECONE_API_ENV\"])\n",
    "\n",
    "index_name=\"myindex\"\n",
    "\n",
    "#Creating Embeddings for Each of The Text Chunks & storing\n",
    "docsearch=PineconeLang.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.pinecone.Pinecone at 0x25b4c62dcd0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we already have an index we can load it like this\n",
    "docsearch=PineconeLang.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"GALE ENCYCLOPEDIA OF MEDICINE 2 117Allergies\\nAllergic rhinitis is commonly triggered by\\nexposure to household dust, animal fur,or pollen. The foreign substance thattriggers an allergic reaction is calledan allergen.\\nThe presence of an allergen causes the\\nbody's lymphocytes to begin producingIgE antibodies. The lymphocytes of an allergy sufferer produce an unusuallylarge amount of IgE.\\nIgE molecules attach to mast\\ncells, which contain histamine.HistaminePollen grains\\nLymphocyte\\nFIRST EXPOSURE\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are Allergies\"\n",
    "\n",
    "docs=docsearch.similarity_search(query, k=3)\n",
    "\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result GALE ENCYCLOPEDIA OF MEDICINE 2 117Allergies\n",
      "Allergic rhinitis is commonly triggered by\n",
      "exposure to household dust, animal fur,or pollen. The foreign substance thattriggers an allergic reaction is calledan allergen.\n",
      "The presence of an allergen causes the\n",
      "body's lymphocytes to begin producingIgE antibodies. The lymphocytes of an allergy sufferer produce an unusuallylarge amount of IgE.\n",
      "IgE molecules attach to mast\n",
      "cells, which contain histamine.HistaminePollen grains\n",
      "Lymphocyte\n",
      "FIRST EXPOSURE\n"
     ]
    }
   ],
   "source": [
    "print(\"Result\", docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_AUTH_TOKEN\"]  = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [12:59<00:00, 779.03s/it]\n"
     ]
    }
   ],
   "source": [
    "#from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "#llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/Llama-2-7B-Chat-GGML\", model_file=\"llama-2-7b-chat.ggmlv3.q8_0.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\smsub\\\\Subahani\\\\Study\\\\Generative AI\\\\chatbotLlama2\\\\GenAI-End-to-End-Medical-chatbot-using-LLAMA2\\\\model\\\\llama-2-7b-chat.ggmlv3.q8_0.bin'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from huggingface_hub import hf_hub_download\n",
    "\n",
    "## https://huggingface.co/docs/huggingface_hub/v0.16.3/en/package_reference/file_download#huggingface_hub.hf_hub_download\n",
    "#hf_hub_download(\n",
    "    #repo_id=\"TheBloke/Llama-2-7B-Chat-GGML\",\n",
    "    #filename=\"llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
    "    #local_dir=r\"C:\\Users\\smsub\\Subahani\\Study\\Generative AI\\chatbotLlama2\\GenAI-End-to-End-Medical-chatbot-using-LLAMA2\\model\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smsub\\Anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :  Acne is a common skin disease characterized by pimples on the face, chest, and back. It occurs when the pores of the skin become clogged with oil, dead skin cells, and bacteria.\n",
      "Response :  Psychotherapy is a type of treatment that helps people manage their mental health issues by talking with a trained mental health professional.\n",
      "Response :  GBS (Group B streptococci) is a type of bacteria that, if passed to a baby during birth, can cause infection in the baby's lungs, bloodstream, or brain. GBS is a common cause of infections in newborns and can be dangerous, especially for premature babies.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt:\")\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
